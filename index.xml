<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Haozhe Su on Haozhe Su</title>
    <link>https://SoldierDown.github.io/</link>
    <description>Recent content in Haozhe Su on Haozhe Su</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2019 Haozhe Su</copyright>
    <lastBuildDate>Sat, 06 Oct 2018 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Code for Weakly-Supervised GANs (WS-GAN)</title>
      <link>https://SoldierDown.github.io/post/ws-gan/</link>
      <pubDate>Sat, 01 Dec 2018 00:00:00 -0500</pubDate>
      
      <guid>https://SoldierDown.github.io/post/ws-gan/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Checkout the code&lt;/strong&gt; on &lt;a href=&#34;https://github.com/phymhan/ws-gan&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;Github&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;PyTorch code for &amp;ldquo;Learning Facial Attribute Modeling with Weakly Supervised GANs&amp;rdquo;. The code is largely based on &lt;a href=&#34;https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix&#34; target=&#34;_blank&#34;&gt;CycleGAN and pix2pix&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning Facial Attribute Modeling with Weakly Supervised GANs</title>
      <link>https://SoldierDown.github.io/publication/ws-gan/</link>
      <pubDate>Sat, 01 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://SoldierDown.github.io/publication/ws-gan/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning Generative Models of Tissue Organization with Supervised GANs</title>
      <link>https://SoldierDown.github.io/publication/supervised-gan/</link>
      <pubDate>Fri, 19 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://SoldierDown.github.io/publication/supervised-gan/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Deep Contextual Recurrent Residual Networks for Scene Labeling</title>
      <link>https://SoldierDown.github.io/publication/deep_contextual_rnn/</link>
      <pubDate>Sun, 07 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://SoldierDown.github.io/publication/deep_contextual_rnn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Study of  </title>
      <link>https://SoldierDown.github.io/project/physics_urp/</link>
      <pubDate>Fri, 15 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://SoldierDown.github.io/project/physics_urp/</guid>
      <description>&lt;p&gt;This is the project for &amp;ldquo;Learning Generative Models of Tissue Organization with Supervised GANs&amp;rdquo;. Please see more in &lt;strong&gt;Publication&lt;/strong&gt; section.&lt;/p&gt;

&lt;a href=&#34;https://SoldierDown.github.io/pdf/10701_report.pdf&#34;&gt;[&lt;strong&gt;View my presentation&lt;/strong&gt;]&lt;/a&gt;
</description>
    </item>
    
    <item>
      <title>Code for Supervised GANs (SGAN)</title>
      <link>https://SoldierDown.github.io/post/supervised-gan/</link>
      <pubDate>Fri, 01 Dec 2017 00:00:00 -0500</pubDate>
      
      <guid>https://SoldierDown.github.io/post/supervised-gan/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Checkout the code&lt;/strong&gt; on &lt;a href=&#34;https://github.com/phymhan/supervised-gan&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;Github&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;PyTorch code for &amp;ldquo;Learning Generative Models of Tissue Organization with Supervised GANs&amp;rdquo;. The code is largely based on &lt;a href=&#34;https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix&#34; target=&#34;_blank&#34;&gt;CycleGAN and pix2pix&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An Automated Blood Cell Detection and Segmentation System</title>
      <link>https://SoldierDown.github.io/publication/automatic-cell/</link>
      <pubDate>Mon, 13 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://SoldierDown.github.io/publication/automatic-cell/</guid>
      <description></description>
    </item>
    
    <item>
      <title>MatConvNet modules for 2-D RNNs (LSTM, GRU)</title>
      <link>https://SoldierDown.github.io/post/lstm2d/</link>
      <pubDate>Wed, 15 Feb 2017 00:00:00 -0500</pubDate>
      
      <guid>https://SoldierDown.github.io/post/lstm2d/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Checkout the code&lt;/strong&gt; on &lt;a href=&#34;https://github.com/phymhan/matconvnet&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;Github&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Implementation of various &lt;a href=&#34;https://arxiv.org/abs/1509.00552&#34; target=&#34;_blank&#34;&gt;2-D RNN&lt;/a&gt; modules is included:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;2-D RNN&lt;/li&gt;
&lt;li&gt;2-D &lt;a href=&#34;http://colah.github.io/posts/2015-08-Understanding-LSTMs/&#34; target=&#34;_blank&#34;&gt;LSTM&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Vanilla&lt;/li&gt;
&lt;li&gt;With &amp;ldquo;&lt;a href=&#34;ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf&#34; target=&#34;_blank&#34;&gt;peephole connections&lt;/a&gt;&amp;ldquo;&lt;/li&gt;
&lt;li&gt;With &lt;em&gt;coupled&lt;/em&gt; forget and input gates&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;2-D &lt;a href=&#34;http://arxiv.org/pdf/1406.1078v3.pdf&#34; target=&#34;_blank&#34;&gt;GRU&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Hierarchical Feature Extraction for Nuclear Morphometry-Based Cancer Diagnosis</title>
      <link>https://SoldierDown.github.io/publication/hierarchical/</link>
      <pubDate>Fri, 21 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://SoldierDown.github.io/publication/hierarchical/</guid>
      <description></description>
    </item>
    
    <item>
      <title>2D Interactive Fluid Simulation</title>
      <link>https://SoldierDown.github.io/project/2d_fluid/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://SoldierDown.github.io/project/2d_fluid/</guid>
      <description>&lt;p&gt;Convolutional neural networks, or CNNs, has been widely applied to various facial related problems, including facial land-marking, individual face matching, and 3D facial reconstruction. Despite its success in robust face detection in terms of performance, there are still some challenges raised by strong illumination, sizes of faces and artifacts. Particularly, in CNN training, the feature extraction and detection results are greatly affected by the structure of the network. Hence, it is desirable to be able to perform some kind of analysis on convolution neural nets, such as feature map visualization at different stages, which helps design of network structure and tuning of hyper-parameters and thus improves feature extraction as well as classification accuracy.&lt;/p&gt;

&lt;p&gt;Our project aims to propose and evaluate different visualization strategies for face detection models, which is composed of two steps:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;In the first step, we train a face detection model. We first transform the state-of-art Faster-RCNN on object detection to the face detection problem. The modified RCNN model is then tested on challenging face images, including the Wider Face dataset and the pre-trained model for CNN is the VGG-16. For implementation we use Caffe as the CNN framework.&lt;/li&gt;
&lt;li&gt;In the second step we evaluate and visualize our model using the proposed classifier probes, which is based on computing the conditional entropy. Basically, the (average) conditional entropy of class given activation values quantifies the average amount of information of classes needed when activation values are known. Ideally, from bottom to top (from bottom image layer to top convolutional layer), we would expect the average conditional entropy goes down.&lt;/li&gt;
&lt;/ul&gt;

&lt;a href=&#34;https://SoldierDown.github.io/pdf/Term_Project.pdf&#34;&gt;[&lt;strong&gt;View our technical report&lt;/strong&gt;]&lt;/a&gt;
</description>
    </item>
    
    <item>
      <title>3D Animation for Education Purpose</title>
      <link>https://SoldierDown.github.io/project/educational/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://SoldierDown.github.io/project/educational/</guid>
      <description>&lt;p&gt;Convolutional neural networks, or CNNs, has been widely applied to various facial related problems, including facial land-marking, individual face matching, and 3D facial reconstruction. Despite its success in robust face detection in terms of performance, there are still some challenges raised by strong illumination, sizes of faces and artifacts. Particularly, in CNN training, the feature extraction and detection results are greatly affected by the structure of the network. Hence, it is desirable to be able to perform some kind of analysis on convolution neural nets, such as feature map visualization at different stages, which helps design of network structure and tuning of hyper-parameters and thus improves feature extraction as well as classification accuracy.&lt;/p&gt;

&lt;p&gt;Our project aims to propose and evaluate different visualization strategies for face detection models, which is composed of two steps:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;In the first step, we train a face detection model. We first transform the state-of-art Faster-RCNN on object detection to the face detection problem. The modified RCNN model is then tested on challenging face images, including the Wider Face dataset and the pre-trained model for CNN is the VGG-16. For implementation we use Caffe as the CNN framework.&lt;/li&gt;
&lt;li&gt;In the second step we evaluate and visualize our model using the proposed classifier probes, which is based on computing the conditional entropy. Basically, the (average) conditional entropy of class given activation values quantifies the average amount of information of classes needed when activation values are known. Ideally, from bottom to top (from bottom image layer to top convolutional layer), we would expect the average conditional entropy goes down.&lt;/li&gt;
&lt;/ul&gt;

&lt;a href=&#34;https://SoldierDown.github.io/pdf/Term_Project.pdf&#34;&gt;[&lt;strong&gt;View our technical report&lt;/strong&gt;]&lt;/a&gt;
</description>
    </item>
    
    <item>
      <title>3D Modeling: Bear-Claw Knife, Elevator and Other Stuffs</title>
      <link>https://SoldierDown.github.io/project/3danse_cp/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://SoldierDown.github.io/project/3danse_cp/</guid>
      <description>&lt;p&gt;Convolutional neural networks, or CNNs, has been widely applied to various facial related problems, including facial land-marking, individual face matching, and 3D facial reconstruction. Despite its success in robust face detection in terms of performance, there are still some challenges raised by strong illumination, sizes of faces and artifacts. Particularly, in CNN training, the feature extraction and detection results are greatly affected by the structure of the network. Hence, it is desirable to be able to perform some kind of analysis on convolution neural nets, such as feature map visualization at different stages, which helps design of network structure and tuning of hyper-parameters and thus improves feature extraction as well as classification accuracy.&lt;/p&gt;

&lt;p&gt;Our project aims to propose and evaluate different visualization strategies for face detection models, which is composed of two steps:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;In the first step, we train a face detection model. We first transform the state-of-art Faster-RCNN on object detection to the face detection problem. The modified RCNN model is then tested on challenging face images, including the Wider Face dataset and the pre-trained model for CNN is the VGG-16. For implementation we use Caffe as the CNN framework.&lt;/li&gt;
&lt;li&gt;In the second step we evaluate and visualize our model using the proposed classifier probes, which is based on computing the conditional entropy. Basically, the (average) conditional entropy of class given activation values quantifies the average amount of information of classes needed when activation values are known. Ideally, from bottom to top (from bottom image layer to top convolutional layer), we would expect the average conditional entropy goes down.&lt;/li&gt;
&lt;/ul&gt;

&lt;a href=&#34;https://SoldierDown.github.io/pdf/Term_Project.pdf&#34;&gt;[&lt;strong&gt;View our technical report&lt;/strong&gt;]&lt;/a&gt;
</description>
    </item>
    
    <item>
      <title>Image Warping</title>
      <link>https://SoldierDown.github.io/project/cg_iw_cp/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://SoldierDown.github.io/project/cg_iw_cp/</guid>
      <description>&lt;p&gt;Convolutional neural networks, or CNNs, has been widely applied to various facial related problems, including facial land-marking, individual face matching, and 3D facial reconstruction. Despite its success in robust face detection in terms of performance, there are still some challenges raised by strong illumination, sizes of faces and artifacts. Particularly, in CNN training, the feature extraction and detection results are greatly affected by the structure of the network. Hence, it is desirable to be able to perform some kind of analysis on convolution neural nets, such as feature map visualization at different stages, which helps design of network structure and tuning of hyper-parameters and thus improves feature extraction as well as classification accuracy.&lt;/p&gt;

&lt;p&gt;Our project aims to propose and evaluate different visualization strategies for face detection models, which is composed of two steps:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;In the first step, we train a face detection model. We first transform the state-of-art Faster-RCNN on object detection to the face detection problem. The modified RCNN model is then tested on challenging face images, including the Wider Face dataset and the pre-trained model for CNN is the VGG-16. For implementation we use Caffe as the CNN framework.&lt;/li&gt;
&lt;li&gt;In the second step we evaluate and visualize our model using the proposed classifier probes, which is based on computing the conditional entropy. Basically, the (average) conditional entropy of class given activation values quantifies the average amount of information of classes needed when activation values are known. Ideally, from bottom to top (from bottom image layer to top convolutional layer), we would expect the average conditional entropy goes down.&lt;/li&gt;
&lt;/ul&gt;

&lt;a href=&#34;https://SoldierDown.github.io/pdf/Term_Project.pdf&#34;&gt;[&lt;strong&gt;View our technical report&lt;/strong&gt;]&lt;/a&gt;
</description>
    </item>
    
    <item>
      <title>Rigid Body Simulation</title>
      <link>https://SoldierDown.github.io/project/rbs/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://SoldierDown.github.io/project/rbs/</guid>
      <description>&lt;p&gt;Convolutional neural networks, or CNNs, has been widely applied to various facial related problems, including facial land-marking, individual face matching, and 3D facial reconstruction. Despite its success in robust face detection in terms of performance, there are still some challenges raised by strong illumination, sizes of faces and artifacts. Particularly, in CNN training, the feature extraction and detection results are greatly affected by the structure of the network. Hence, it is desirable to be able to perform some kind of analysis on convolution neural nets, such as feature map visualization at different stages, which helps design of network structure and tuning of hyper-parameters and thus improves feature extraction as well as classification accuracy.&lt;/p&gt;

&lt;p&gt;Our project aims to propose and evaluate different visualization strategies for face detection models, which is composed of two steps:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;In the first step, we train a face detection model. We first transform the state-of-art Faster-RCNN on object detection to the face detection problem. The modified RCNN model is then tested on challenging face images, including the Wider Face dataset and the pre-trained model for CNN is the VGG-16. For implementation we use Caffe as the CNN framework.&lt;/li&gt;
&lt;li&gt;In the second step we evaluate and visualize our model using the proposed classifier probes, which is based on computing the conditional entropy. Basically, the (average) conditional entropy of class given activation values quantifies the average amount of information of classes needed when activation values are known. Ideally, from bottom to top (from bottom image layer to top convolutional layer), we would expect the average conditional entropy goes down.&lt;/li&gt;
&lt;/ul&gt;

&lt;a href=&#34;https://SoldierDown.github.io/pdf/&#34;&gt;[&lt;strong&gt;View our technical report&lt;/strong&gt;]&lt;/a&gt;
</description>
    </item>
    
    <item>
      <title>This is Us</title>
      <link>https://SoldierDown.github.io/project/pnd/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://SoldierDown.github.io/project/pnd/</guid>
      <description>&lt;p&gt;Convolutional neural networks, or CNNs, has been widely applied to various facial related problems, including facial land-marking, individual face matching, and 3D facial reconstruction. Despite its success in robust face detection in terms of performance, there are still some challenges raised by strong illumination, sizes of faces and artifacts. Particularly, in CNN training, the feature extraction and detection results are greatly affected by the structure of the network. Hence, it is desirable to be able to perform some kind of analysis on convolution neural nets, such as feature map visualization at different stages, which helps design of network structure and tuning of hyper-parameters and thus improves feature extraction as well as classification accuracy.&lt;/p&gt;

&lt;p&gt;Our project aims to propose and evaluate different visualization strategies for face detection models, which is composed of two steps:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;In the first step, we train a face detection model. We first transform the state-of-art Faster-RCNN on object detection to the face detection problem. The modified RCNN model is then tested on challenging face images, including the Wider Face dataset and the pre-trained model for CNN is the VGG-16. For implementation we use Caffe as the CNN framework.&lt;/li&gt;
&lt;li&gt;In the second step we evaluate and visualize our model using the proposed classifier probes, which is based on computing the conditional entropy. Basically, the (average) conditional entropy of class given activation values quantifies the average amount of information of classes needed when activation values are known. Ideally, from bottom to top (from bottom image layer to top convolutional layer), we would expect the average conditional entropy goes down.&lt;/li&gt;
&lt;/ul&gt;

&lt;a href=&#34;https://SoldierDown.github.io/pdf/Term_Project.pdf&#34;&gt;[&lt;strong&gt;View our technical report&lt;/strong&gt;]&lt;/a&gt;
</description>
    </item>
    
  </channel>
</rss>
